{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b56600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import math\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbba9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu_to_use = max(1, mp.cpu_count() - 2)\n",
    "print(f\"Cores to use: {cpu_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcc4db",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc36549",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ed7f5",
   "metadata": {},
   "source": [
    "## natasha tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "morph_tagger = NewsMorphTagger(NewsEmbedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84531ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_texts(df, drop_rate=None):\n",
    "    docs_tokens = []\n",
    "    \n",
    "    texts = df['text'].tolist()\n",
    "    for text in tqdm(texts):\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "\n",
    "        if drop_rate:\n",
    "            mask_drop = np.random.rand(len(doc.tokens))\n",
    "            mask_drop[mask_drop > drop_rate] = 0\n",
    "            mask_drop[mask_drop != 0] = 1        \n",
    "        \n",
    "        tokens = []\n",
    "        for i, token in enumerate(doc.tokens):\n",
    "            token.lemmatize(morph_vocab)\n",
    "            if re.match('[а-яa-z]+(-[а-яa-z]+)*$', token.lemma):\n",
    "                # Drop words\n",
    "                if not drop_rate or mask_drop[i] == 0:\n",
    "                    tokens.append(token.lemma)\n",
    "\n",
    "        docs_tokens.append(tokens)\n",
    "    \n",
    "    return docs_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d0ac2",
   "metadata": {},
   "source": [
    "## evaluating scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scorer(threshold=0.20, confidence=1.2):\n",
    "    def scorer(y, y_probas):\n",
    "        score = 0.\n",
    "        for i in range(len(y)):\n",
    "            probas = np.sort(y_probas[i])\n",
    "            if probas[-1] > threshold and probas[-1] > confidence * probas[-2]:\n",
    "                max_ = probas[-1]\n",
    "                label = np.where(y_probas[i] == probas[-1])[0]\n",
    "                score += 1 if label == y[i] else -1\n",
    "                \n",
    "        return score / len(y)\n",
    "    \n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(raw_outputs, eval_df, coefs=None, out_dict=False):\n",
    "    median_outputs = np.array([output.sum(axis=0) for output in raw_outputs])\n",
    "    \n",
    "    probs = softmax(median_outputs, axis=1)\n",
    "    if not coefs is None:\n",
    "        probs *= coefs\n",
    "    score = get_scorer(0.0, 1.)(eval_df['label'].to_list(), probs)\n",
    "    \n",
    "    report = classification_report(eval_df['label'].to_list(), predictions, output_dict=out_dict)\n",
    "    \n",
    "    return score, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7e202",
   "metadata": {},
   "source": [
    "## Create Dataset for simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_df(df):\n",
    "    grouped_df = df.groupby('oid').agg({\n",
    "        'category'    : min,\n",
    "        'text'        : lambda texts : ' '.join(texts)})\n",
    "    grouped_df.index = range(len(grouped_df))\n",
    "    \n",
    "    grouped_df.columns = ['label', 'text']\n",
    "    grouped_df = grouped_df[['text', 'label']]\n",
    "    \n",
    "    grouped_df[\"label\"] = grouped_df[\"label\"].astype(\"category\")\n",
    "    cat_dict = dict(enumerate(grouped_df[\"label\"].cat.categories))\n",
    "    grouped_df[\"label\"] = grouped_df[\"label\"].cat.codes\n",
    "    \n",
    "    return grouped_df, cat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e838b",
   "metadata": {},
   "source": [
    "### Group data and map labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ac499",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf, cat_dict = group_df(df)\n",
    "num_classes = len(cat_dict)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20baddef",
   "metadata": {},
   "source": [
    "### Train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, eval_df = train_test_split(gdf, test_size=0.2, stratify = gdf['label'])\n",
    "len(train_df), len(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ae391",
   "metadata": {},
   "source": [
    "### Normalize val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c14131",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_words = filter_texts(eval_df, drop_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbc34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"text\"] = [\" \".join(words) for words in docs_words]\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b88d5",
   "metadata": {},
   "source": [
    "### Augment train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter tokens (valid words)\n",
    "docs_words = filter_texts(train_df, drop_rate=None)\n",
    "docs_words_dropped = filter_texts(train_df, drop_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400387f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist([len(words) for words in docs_words])\n",
    "_ = plt.hist([len(words) for words in docs_words_dropped])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1253e02",
   "metadata": {},
   "source": [
    "### Spam words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c36ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for words in docs_words:\n",
    "    for word in words:\n",
    "        vocab.setdefault(word, 0)\n",
    "        vocab[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(reversed(sorted(vocab.items(), key=lambda item: item[1])))\n",
    "list(vocab.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('.*token.*')\n",
    "SPAM = set([word for word in vocab.keys() if p.match(word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['в', 'и', 'на', 'с', 'быть', 'что', 'я', 'по', 'это', 'весь', 'он', 'мы', 'за', 'тот', 'для', 'а', 'из', \n",
    "    'но', 'который', 'как', 'этот', 'к', 'у', 'о', 'от', 'до', 'уже', 'еще', 'чтобы', 'кто', 'или', 'только', 'такой', \n",
    "    'при', 'когда', 'же', 'бы', 'также', 'какой', 'то', 'даже', 'под', 'ли', 'вот', 'потому', 'чем', 'перед', 'пока', 'там']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ul in useless:\n",
    "    SPAM.add(ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b28f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(words):\n",
    "    filtered = []\n",
    "    for word in words:\n",
    "        if not word in SPAM:\n",
    "            filtered.append(word)\n",
    "            \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e811831",
   "metadata": {},
   "source": [
    "### Build train DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dropped = train_df.copy()\n",
    "train_df[\"text\"] = [\" \".join(filter_words(words)) for words in docs_words]\n",
    "train_dropped[\"text\"] = [\" \".join(filter_words(words)) for words in docs_words_dropped]\n",
    "train_df = pd.concat([train_df, train_dropped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41420d",
   "metadata": {},
   "source": [
    "### Save train and val DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('cache_dfs/train_df.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(filepath, index=True)\n",
    "\n",
    "filepath = Path('cache_dfs/eval_df.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "eval_df.to_csv(filepath, index=True)\n",
    "\n",
    "with open('cache_dfs/cats.pkl', 'wb') as f:\n",
    "    pickle.dump(cat_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b2335",
   "metadata": {},
   "source": [
    "### Load train and val DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f486105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('cache_dfs/train_df.csv', index_col=0)\n",
    "eval_df = pd.read_csv('cache_dfs/eval_df.csv', index_col=0)\n",
    "\n",
    "with open('cache_dfs/cats.pkl', 'rb') as f:\n",
    "    cat_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e720ff7",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n):\n",
    "    sub_train_df = train_df.sample(len(train_df), replace=True)\n",
    "    subsets.append(sub_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d97ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89f429",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73156e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78796d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc9ae4",
   "metadata": {},
   "source": [
    "### RuBERT-conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd619fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 2\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-1476-epoch-3\", \"checkpoint-792-epoch-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=128,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=3,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f\"models/rubert-base-cased-conversational/last{i}\"\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"bert\", \n",
    "        f\"models/rubert-base-cased-conversational\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"),\n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc82a02",
   "metadata": {},
   "source": [
    "### RuBERT-sber-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca38071",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 2\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-11814-epoch-3\", \"checkpoint-6339-epoch-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fa9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=16,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=3,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f'models/sberbank_ruBert_large/last{i}'\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"bert\", \n",
    "        f\"models/sberbank_ruBert_large\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"), \n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a0710",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 2\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-5378-epoch-2\", \"checkpoint-2842-epoch-2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=32,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=2,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f'models/xlm-roberta-large-qa-multilingual-finedtuned-ru/last{i}'\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"xlmroberta\", \n",
    "        f\"models/xlm-roberta-large-qa-multilingual-finedtuned-ru\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"), \n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f96df4",
   "metadata": {},
   "source": [
    "### Sber RuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a21d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 1\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-792-epoch-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92132c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=128,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=3,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f\"models/sber-rubert/last{i}\"\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"bert\", \n",
    "        f\"models/sber-rubert\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"),\n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c5e2f",
   "metadata": {},
   "source": [
    "### RuBERT sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 1\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-798-epoch-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=128,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=3,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f\"models/rubert-sentence/last{i}\"\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"bert\", \n",
    "        f\"models/rubert-sentence\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"),\n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d098a51",
   "metadata": {},
   "source": [
    "### RuBERT-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5368540",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_models = 1\n",
    "strides = [0.8, 0.4]\n",
    "ckpt = [\"checkpoint-816-epoch-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216cae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_distinct_models):\n",
    "    model_args = ClassificationArgs(\n",
    "        train_batch_size=128,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs=3,\n",
    "        overwrite_output_dir=True,\n",
    "        sliding_window=True,\n",
    "        stride=strides[i],\n",
    "        weight_decay=1e-8,\n",
    "        output_dir=f\"models/rubert-base-cased/last{i}\"\n",
    "    )\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        \"bert\", \n",
    "        f\"models/rubert-base-cased\" + (f\"/last{i}/{ckpt[i]}\" if load else \"\"),\n",
    "        num_labels=num_classes,\n",
    "        args=model_args\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23762079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Models: \")\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"{i : >2}. {model.config._name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fcbe1",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_preds(preds, num_classes):\n",
    "    voted_preds = []\n",
    "    ties = 0\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = [0 for _ in range(num_classes)]\n",
    "        for j in range(len(preds)):\n",
    "            votes[preds[j][i]] += 1\n",
    "\n",
    "        tie = sorted(votes)\n",
    "        if tie[-1] == tie[-2]:\n",
    "            print(f\"tie {i}: {votes}\")\n",
    "            ties += 1\n",
    "            voted_preds.append(-1)\n",
    "        else:\n",
    "            voted_preds.append(votes.index(tie[-1]))\n",
    "    return voted_preds, ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485db764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_probas(probas, num_classes):\n",
    "    voted_preds = []\n",
    "    ties = 0\n",
    "    for i in range(len(probas[0])):\n",
    "        votes = [0 for _ in range(num_classes)]\n",
    "        for j in range(len(probas)):\n",
    "            for t in range(num_classes):\n",
    "                votes[t] += probas[j][i][t]\n",
    "\n",
    "        tie = sorted(votes)\n",
    "        if tie[-1] < tie[-2] * 1.01:\n",
    "            print(f\"tie {i}: {votes}\")\n",
    "            ties += 1\n",
    "            voted_preds.append(-1)\n",
    "        else:\n",
    "            voted_preds.append(votes.index(tie[-1]))\n",
    "    return voted_preds, ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b52ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    model.train_model(subsets[i])\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f1b3e",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6ca5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "preds = []\n",
    "raws = []\n",
    "for model in models:\n",
    "    predictions, raw_outputs = model.predict(eval_df['text'].to_list())\n",
    "    score, _ = evaluate(raw_outputs, eval_df)\n",
    "    raws.append(raw_outputs)\n",
    "    preds.append(predictions)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f44427",
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_preds, ties = agg_preds(preds, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probas = []\n",
    "# for i in range(len(raws)):\n",
    "#     median_outputs = np.array([output.sum(axis=0) for output in raws[i]])\n",
    "#     softs = softmax(median_outputs, axis=1)\n",
    "#     probas.append(softs)\n",
    "# voted_preds, ties = agg_probas(probas, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_real = np.array(eval_df['label'].tolist())\n",
    "labels_pred = np.array(voted_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc083ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = (np.count_nonzero(labels_real == labels_pred) - np.count_nonzero(labels_real != labels_pred) + ties) / len(eval_df)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce744c94",
   "metadata": {},
   "source": [
    "## Create commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd0c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df = test_df.groupby('oid').agg({'text' : lambda texts: ' '.join(texts)})\n",
    "oids = test_df.index\n",
    "test_df.index = range(len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_words = filter_texts(test_df, drop_rate=None)\n",
    "test_df['text'] = [\" \".join(filter_words(words)) for words in test_valid_words]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c7462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_test = []\n",
    "raws_test = []\n",
    "for model in models:\n",
    "    predictions, raw_outputs = model.predict(test_df['text'].to_list())\n",
    "    raws_test.append(raw_outputs)\n",
    "    preds_test.append(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747222b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_preds, ties = agg_preds(preds_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probas_test = []\n",
    "# for i in range(len(raws_test)):\n",
    "#     median_outputs = np.array([output.sum(axis=0) for output in raws_test[i]])\n",
    "#     softs = softmax(median_outputs, axis=1)\n",
    "#     probas_test.append(softs)\n",
    "        \n",
    "# voted_preds, ties = agg_probas(probas_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f84985",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.DataFrame({'oid':oids, 'category':voted_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.set_index('oid')\n",
    "csv = csv[csv['category'] > -1]\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8be332",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['category'] = csv['category'].map(lambda cat: cat_dict[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34793b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('cache_dfs/submission.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "csv.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
