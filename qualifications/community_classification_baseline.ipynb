{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b56600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu_to_use = max(1, mp.cpu_count() - 2)\n",
    "print(f\"Cores to use: {cpu_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcc4db",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc36549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c938cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86038d61",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4766a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "morph_tagger = NewsMorphTagger(NewsEmbedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document():\n",
    "    def __init__(self, id_=0):\n",
    "        self.id = id_\n",
    "        self.word_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_documents(df):\n",
    "    docs_tokens = []\n",
    "    \n",
    "    texts = df['text'].tolist()\n",
    "    for text in tqdm(texts):\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "\n",
    "        tokens = []\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(morph_vocab)\n",
    "            if re.match('[а-яa-z]+(-[а-яa-z]+)*$', token.lemma):\n",
    "                tokens.append(token.lemma)\n",
    "        docs_tokens.append(tokens)\n",
    "    return docs_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f86612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary and index\n",
    "def get_vocab(docs_tokens):\n",
    "    vocab = []\n",
    "    word_index = {}\n",
    "\n",
    "    for tokens in tqdm(docs_tokens):\n",
    "        for word in tokens:\n",
    "            if not word in word_index:\n",
    "                vocab.append(word)\n",
    "                word_index[word] = len(vocab) - 1\n",
    "    return vocab, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate word counts for documents\n",
    "def get_docs(docs_tokens, word_index):\n",
    "    docs = []\n",
    "    \n",
    "    for i, tokens in enumerate(tqdm(docs_tokens)):\n",
    "        doc = Document(i)\n",
    "        doc.total = len(tokens)\n",
    "        doc.word_counts[-1] = 0\n",
    "        for token in tokens:\n",
    "            if token not in word_index:\n",
    "                doc.word_counts[-1] += 1\n",
    "                continue\n",
    "            idx = word_index[token]\n",
    "            doc.word_counts.setdefault(idx, 0)\n",
    "            doc.word_counts[idx] += 1\n",
    "        docs.append(doc)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ac499",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.groupby('oid').agg({\n",
    "    'category'    : min, \n",
    "    'text'        : lambda x: ' '.join(x)},)\n",
    "gdf.index = range(len(gdf))\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words for all documents\n",
    "docs_words = tokenize_documents(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get encoded labels for all documents\n",
    "le = LabelEncoder()\n",
    "docs_labels = le.fit_transform(gdf['category'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified train/val split\n",
    "words_train, words_val, Y_train, Y_val = train_test_split(docs_words, docs_labels, test_size=0.2, stratify=docs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9bb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_train), len(words_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1479f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary and index from train documents\n",
    "vocab, word_index = get_vocab(words_train)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate word count stats for train and val documents\n",
    "docs_train = get_docs(words_train, word_index)\n",
    "docs_val = get_docs(words_val, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_freq(vocab, docs):\n",
    "    # calculate document frequency for words\n",
    "    doc_freq = [0 for _ in range(len(vocab))]\n",
    "    for doc in tqdm(docs):\n",
    "        for i in doc.word_counts:\n",
    "            doc_freq[i] += 1\n",
    "    return doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(vocab, docs, doc_freq):  \n",
    "    tf_idf = [[0 for _ in range(len(vocab))] for _ in range(len(docs))]\n",
    "    for i in tqdm(range(len(docs))):\n",
    "        for word in docs[i].word_counts:\n",
    "            tf_idf[i][word] = docs[i].word_counts.get(word, 0)\n",
    "            tf_idf[i][word] /= docs[i].total\n",
    "            tf_idf[i][word] *= math.log(len(docs) / doc_freq[word])\n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5186bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq = get_doc_freq(vocab, docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbfffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = get_tf_idf(vocab, docs_train, doc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_val = get_tf_idf(vocab, docs_val, doc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b249f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf_idf_train), len(tf_idf_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf_idf_val), len(tf_idf_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad09339",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scorer(threshold=0.1, confidence=1.01):\n",
    "    def scorer(y, y_probas):\n",
    "        score = 0.\n",
    "        for i in range(len(y)):\n",
    "            probas = np.sort(y_probas[i])\n",
    "            if probas[-1] > threshold and probas[-1] > confidence * probas[-2]:\n",
    "                max_ = probas[-1]\n",
    "                label = np.where(y_probas[i] == probas[-1])[0]\n",
    "                score += 1 if label == y[i] else -1\n",
    "                \n",
    "        return score / len(y)\n",
    "    \n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae482e0",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = csr_matrix(tf_idf_train)\n",
    "matrix_val = csr_matrix(tf_idf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760694aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1024, n_iter=10, random_state=42)\n",
    "svd.fit(matrix_train)\n",
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c27edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(svd.transform(tf_idf_train))\n",
    "\n",
    "X_val = scaler.transform(svd.transform(tf_idf_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccbfbe1",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b093ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "y_probas = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_scorer(0.1, 1.01)(Y_val, y_probas)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
