{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import implicit\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "import umap\n",
    "import wandb\n",
    "\n",
    "\n",
    "from implicit.evaluation import ndcg_at_k, leave_k_out_split\n",
    "from random import randint\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('data/train.parquet.gzip')\n",
    "\n",
    "items_meta = pd.read_parquet('data/items_meta.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = len(items_meta.item_id.unique())\n",
    "num_users = len(train.user_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add post features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_stats = train.groupby('item_id').agg(\n",
    "    avg_time  = pd.NamedAgg(column = 'timespent', aggfunc = 'mean'),\n",
    "    users_cnt = pd.NamedAgg(column = 'user_id',   aggfunc = lambda x: len(set(x))),\n",
    "    likes     = pd.NamedAgg(column = 'reaction',  aggfunc = lambda x: (x == 1).sum()),\n",
    "    dislikes  = pd.NamedAgg(column = 'reaction',  aggfunc = lambda x: (x == -1).sum()),\n",
    "    rating    = pd.NamedAgg(column = 'reaction',  aggfunc = lambda x: x.sum()/len(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227606, 316)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array(items_meta['embeddings'].tolist())\n",
    "extended_embeddings = np.hstack([embeddings, items_stats[['avg_time', 'users_cnt', 'likes', 'dislikes']].values])\n",
    "extended_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "extended_embeddings = scaler.fit_transform(extended_embeddings)\n",
    "awesome_embeddings = extended_embeddings[:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3415"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del items_stats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train | Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_k_out_split(user_item_df, k = 5, train_ratio=0.8):\n",
    "    df_gr = user_item_df.groupby('user_id').agg(\n",
    "        item_ids = pd.NamedAgg(column = 'item_id', aggfunc = lambda x: x.tolist()),\n",
    "        timespents = pd.NamedAgg(column = 'timespent', aggfunc = lambda x: x.tolist()),\n",
    "        reactions = pd.NamedAgg(column = 'reaction', aggfunc = lambda x: x.tolist()))\n",
    "    \n",
    "    train_user_item_df = pd.DataFrame(columns=df_gr.columns)\n",
    "    train_user_item_df['user_id'] = df_gr.index\n",
    "    train_user_item_df.set_index('user_id')\n",
    "    \n",
    "    test_user_item_df = pd.DataFrame(columns=df_gr.columns)\n",
    "    test_user_item_df['user_id'] = df_gr.index\n",
    "    test_user_item_df.set_index('user_id')\n",
    "    \n",
    "    df_gr['train_size'] = df_gr.item_ids.apply(lambda ids: max(len(ids)-k, int(len(ids)*train_ratio + 1)))\n",
    "    \n",
    "    train_user_item_df['item_ids'] = df_gr.apply(lambda row: row.item_ids[:row.train_size], axis=1)\n",
    "    test_user_item_df['item_ids'] = df_gr.apply(lambda row: row.item_ids[row.train_size:], axis=1)\n",
    "    \n",
    "    train_user_item_df['timespents'] = df_gr.apply(lambda row: row.timespents[:row.train_size], axis=1)\n",
    "    test_user_item_df['timespents'] = df_gr.apply(lambda row: row.timespents[row.train_size:], axis=1)\n",
    "    \n",
    "    train_user_item_df['reactions'] = df_gr.apply(lambda row: row.reactions[:row.train_size], axis=1)\n",
    "    test_user_item_df['reactions'] = df_gr.apply(lambda row: row.reactions[row.train_size:], axis=1)\n",
    "    \n",
    "    del df_gr\n",
    "    \n",
    "    return train_user_item_df, test_user_item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 3.64 s, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, val_df = leave_last_k_out_split(train, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_ids</th>\n",
       "      <th>timespents</th>\n",
       "      <th>reactions</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[35236, 186864, 58724, 155390, 153029, 28510, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[46502, 93689, 78282, 33169, 48174, 124953, 47...</td>\n",
       "      <td>[0, 2, 1, 1, 0, 7, 1, 0, 0, 0, 4, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[68210, 64859, 180839, 214379, 31131, 195952, ...</td>\n",
       "      <td>[0, 2, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 10, 0, 2,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            item_ids  \\\n",
       "0  [35236, 186864, 58724, 155390, 153029, 28510, ...   \n",
       "1  [46502, 93689, 78282, 33169, 48174, 124953, 47...   \n",
       "2  [68210, 64859, 180839, 214379, 31131, 195952, ...   \n",
       "\n",
       "                                          timespents  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, ...   \n",
       "1  [0, 2, 1, 1, 0, 7, 1, 0, 0, 0, 4, 0, 0, 0, 0, ...   \n",
       "2  [0, 2, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 10, 0, 2,...   \n",
       "\n",
       "                                           reactions  user_id  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        1  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...        2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_ids</th>\n",
       "      <th>timespents</th>\n",
       "      <th>reactions</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[167951, 219579, 54416, 198166, 167423]</td>\n",
       "      <td>[0, 2, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[48065, 17060, 221256, 106414, 198151]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[100402, 213002, 224226, 125070, 48363]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  item_ids       timespents        reactions  \\\n",
       "0  [167951, 219579, 54416, 198166, 167423]  [0, 2, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "1   [48065, 17060, 221256, 106414, 198151]  [0, 0, 0, 0, 1]  [0, 0, 0, 0, 0]   \n",
       "2  [100402, 213002, 224226, 125070, 48363]  [0, 0, 0, 0, 0]  [0, 0, 0, 0, 0]   \n",
       "\n",
       "   user_id  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inverse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_index = train_df['item_ids'].map(lambda x: dict((post_id, i) for i, post_id in enumerate(x)))\n",
    "train_df['inv_index'] = inv_index.values\n",
    "inv_index = val_df['item_ids'].map(lambda x: dict((post_id, i) for i, post_id in enumerate(x)))\n",
    "val_df['inv_index'] = inv_index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_ids</th>\n",
       "      <th>timespents</th>\n",
       "      <th>reactions</th>\n",
       "      <th>user_id</th>\n",
       "      <th>inv_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[35236, 186864, 58724, 155390, 153029, 28510, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{35236: 0, 186864: 1, 58724: 2, 155390: 3, 153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[46502, 93689, 78282, 33169, 48174, 124953, 47...</td>\n",
       "      <td>[0, 2, 1, 1, 0, 7, 1, 0, 0, 0, 4, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{46502: 0, 93689: 1, 78282: 2, 33169: 3, 48174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[68210, 64859, 180839, 214379, 31131, 195952, ...</td>\n",
       "      <td>[0, 2, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 10, 0, 2,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{68210: 0, 64859: 1, 180839: 2, 214379: 3, 311...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            item_ids  \\\n",
       "0  [35236, 186864, 58724, 155390, 153029, 28510, ...   \n",
       "1  [46502, 93689, 78282, 33169, 48174, 124953, 47...   \n",
       "2  [68210, 64859, 180839, 214379, 31131, 195952, ...   \n",
       "\n",
       "                                          timespents  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, ...   \n",
       "1  [0, 2, 1, 1, 0, 7, 1, 0, 0, 0, 4, 0, 0, 0, 0, ...   \n",
       "2  [0, 2, 0, 3, 6, 0, 0, 0, 0, 0, 0, 0, 10, 0, 2,...   \n",
       "\n",
       "                                           reactions  user_id  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        1   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...        2   \n",
       "\n",
       "                                           inv_index  \n",
       "0  {35236: 0, 186864: 1, 58724: 2, 155390: 3, 153...  \n",
       "1  {46502: 0, 93689: 1, 78282: 2, 33169: 3, 48174...  \n",
       "2  {68210: 0, 64859: 1, 180839: 2, 214379: 3, 311...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split interaction set on test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59c8ac6ac2f4b27b6a001ea399534b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144440015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_train = []\n",
    "post_ids = train['item_id'].values\n",
    "user_ids = train['user_id'].values\n",
    "inv_index = train_df['inv_index'].values\n",
    "for i in tqdm(range(len(user_ids))):\n",
    "    post_id = post_ids[i]\n",
    "    is_train.append(post_id in inv_index[user_ids[i]])\n",
    "    \n",
    "train['is_train'] = is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_u_i = train[train['is_train'] == True].reset_index(drop=True).drop(columns=['is_train'])\n",
    "val_u_i = train[train['is_train'] == False].reset_index(drop=True).drop(columns=['is_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del is_train, post_ids, user_ids, inv_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGl0y3kN7uz6"
   },
   "source": [
    "# Matrix Factorization ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1673127943426,
     "user": {
      "displayName": "Anna Potanina",
      "userId": "06055368165215548424"
     },
     "user_tz": -300
    },
    "id": "JwmcZb5J6uTn"
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_feedback(timespent, reaction):\n",
    "    feedback = np.log(timespent + 1).astype(np.float32)\n",
    "    return feedback\n",
    "\n",
    "def create_feedback_matrix(train_df, num_users, num_items):\n",
    "    indices = np.array(flatten(train_df.item_ids.to_list()))\n",
    "    indptr = np.concatenate((np.array([0]), \n",
    "                            train_df.item_ids.apply(lambda ids: len(ids)).values.cumsum()))\n",
    "\n",
    "    timespent = np.array(flatten(train_df.timespents.to_list()))\n",
    "    reaction = np.array(flatten(train_df.reactions.to_list()))\n",
    "    data = get_feedback(timespent, reaction)\n",
    "    del timespent, reaction\n",
    "\n",
    "    feedback = csr_matrix((data, indices, indptr), shape=(num_users, num_items))\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1673129581893,
     "user": {
      "displayName": "Anna Potanina",
      "userId": "06055368165215548424"
     },
     "user_tz": -300
    },
    "id": "iFfk93pt8Rgi",
    "outputId": "293acf5c-14d2-4af0-8d6a-0142c7299572"
   },
   "outputs": [],
   "source": [
    "emb_dim = awesome_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_train = create_feedback_matrix(train_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Fv8N3haJLIYd"
   },
   "outputs": [],
   "source": [
    "user_item_val = create_feedback_matrix(val_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ParameterGrid({\n",
    "        'regularization' : [0.0, 0.1, 0.2, 0.3], \n",
    "        'iterations':[10, 20], \n",
    "        'alpha' : [0.1, 1.0, 10., 100., 1000., 10000.]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best = -1.\n",
    "for params in list(parameters):\n",
    "    mfm = implicit.als.AlternatingLeastSquares(\n",
    "        factors=emb_dim,\n",
    "        calculate_training_loss=True,\n",
    "        num_threads=12,\n",
    "        **params\n",
    "    )\n",
    "    mfm.item_factors = implicit.gpu.Matrix(awesome_embeddings.astype(np.float32))\n",
    "    mfm.fit(user_item_train, show_progress=True)\n",
    "    \n",
    "    val_score = ndcg_at_k(mfm, user_item_train, user_item_val, K=5, num_threads=12)\n",
    "    \n",
    "    if best < val_score:\n",
    "        best = val_score\n",
    "        best_params = params\n",
    "    print(f\"reg={params['regularization']: <10} it={params['iterations']: <10} alpha={params['alpha']: <10} score:{val_score:>15.5f}\")\n",
    "    \n",
    "print(f\"\"\"Best params: \n",
    "    regularization :{best_params['regularization']: >6}\n",
    "    iterations     :{best_params['iterations']: >6}\n",
    "    alpha          :{best_params['alpha']: >6}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1673129627310,
     "user": {
      "displayName": "Anna Potanina",
      "userId": "06055368165215548424"
     },
     "user_tz": -300
    },
    "id": "Ev4sKwEE70ET"
   },
   "outputs": [],
   "source": [
    "model_mf = implicit.als.AlternatingLeastSquares(\n",
    "    factors=emb_dim,\n",
    "    regularization=0.1,\n",
    "    alpha=100.0,\n",
    "    iterations=15,\n",
    "    calculate_training_loss=True,\n",
    "    num_threads=12,\n",
    ")\n",
    "\n",
    "model_mf.item_factors = implicit.gpu.Matrix(awesome_embeddings.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1616fa5cedae484da1ea2b867b313f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mf.fit(user_item_train, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "02c99a828a2449d690eaf910e0b4f56c",
      "07396779500d434d922a886123b9a2e4",
      "5f98d7616ebd4fdf80d4b54e8aa66cc8",
      "e132763b645f4f1f85ceffa38a482848",
      "af737d7b241d447da22258ac77c66af8",
      "2341effce8054ec89481b6a4e4d8d306",
      "ef7f7db472df4e7ea68c87443fb34f2c",
      "d0d3f77eeea34295b215dec33f4bd963",
      "f0a5ee8990cc43c48087a0db8e8d500a",
      "d2219f844808427694d5fbfa9af353a4",
      "41016eb9832b475e8ad3da1f5b392f9e"
     ]
    },
    "executionInfo": {
     "elapsed": 9474,
     "status": "ok",
     "timestamp": 1673129897027,
     "user": {
      "displayName": "Anna Potanina",
      "userId": "06055368165215548424"
     },
     "user_tz": -300
    },
    "id": "rod_9_89GJ8L",
    "outputId": "496e5efb-82a2-4ebc-a91b-1380e71c3200",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a875a6923043e78d2872460a417b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.03376290824772198"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score = ndcg_at_k(model_mf, user_item_train, user_item_val, K=5, num_threads=12)\n",
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mf.save('models/model_mf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mf = model_mf.load('models/model_mf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embs = model_mf.user_factors.to_numpy()\n",
    "item_embs = model_mf.item_factors.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed': 0,\n",
    "    'iters': 500,\n",
    "    'train_bs': 2**7, \n",
    "    'valid_bs': 2**7,\n",
    "    'lr': 1e-4, \n",
    "    'weight_decay': 1e-7,\n",
    "    'num_workers': 16,\n",
    "    'num_samples': 2**20\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional features:\n",
    "    # Self-interaction\n",
    "# User features    \n",
    "    # User activity (# of posts)\n",
    "    # Number of likes\n",
    "    # Number of dislikes\n",
    "    # Average time on post ()\n",
    "# Post features\n",
    "    # Number of likes\n",
    "    # Number of dislikes\n",
    "    # Post popularity (# of users)\n",
    "    # Average timespent\n",
    "\n",
    "item_extra = 4\n",
    "user_extra = 4\n",
    "hidden_dim = 64\n",
    "lstm_num_layers = 1\n",
    "drop_rate = 0.2\n",
    "\n",
    "seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimespentRegressor(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(TimespentRegressor, self).__init__()\n",
    "        self.lstm_in_dim = emb_dim + item_extra + 2 # Item emb + stats + user feedback\n",
    "        self.lstm_out_dim = emb_dim + item_extra + 2\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "    \n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_in_dim, hidden_size=self.lstm_out_dim,\n",
    "                          num_layers=lstm_num_layers, batch_first=True) #lstm\n",
    "        self.bn0 = nn.LayerNorm(self.lstm_out_dim)\n",
    "        self.relu0 = nn.LeakyReLU()\n",
    "        self.dropout0 = nn.Dropout(drop_rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(emb_dim * 2 + user_extra + item_extra + self.lstm_out_dim + 1, hidden_dim, bias=False)\n",
    "        self.bn1 = nn.LayerNorm(hidden_dim)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(drop_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, history, other):\n",
    "        h_0 = torch.zeros(self.lstm_num_layers, history.size(0), self.lstm_out_dim).to(device)\n",
    "        c_0 = torch.zeros(self.lstm_num_layers, history.size(0), self.lstm_out_dim).to(device)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        _, (hn, cn) = self.lstm(history, (h_0, c_0))\n",
    "        hn = hn.view(-1, self.lstm_out_dim) \n",
    "        lstm_out = self.bn0(hn)\n",
    "        lstm_out = self.relu0(lstm_out)\n",
    "        lstm_out = self.dropout0(lstm_out)\n",
    "        \n",
    "        out = self.fc1(torch.cat([lstm_out, other], axis=1))\n",
    "        out = self.bn1(out)    \n",
    "        out = self.relu1(out)  \n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.fc2(out)    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df_u_i, df, items_meta, user_embs, item_embs, seq_len=5, mode='train'):\n",
    "        # Interactions\n",
    "        self.df_u = df_u_i['user_id'].values\n",
    "        self.df_i = df_u_i['item_id'].values\n",
    "        \n",
    "        # Historical repr\n",
    "        self.histories = df['item_ids'].values\n",
    "        self.timespents = df['timespents'].values\n",
    "        self.reactions = df['reactions'].values\n",
    "        self.inv_index = df['inv_index'].values\n",
    "        \n",
    "        # User and item embeddings\n",
    "        self.user_embs = user_embs\n",
    "        self.item_embs = item_embs\n",
    "        \n",
    "        # Item source-user ids\n",
    "        self.items_sources = items_meta['source_id'].values\n",
    "        \n",
    "        # Dataset mode and history len\n",
    "        self.seq_len = seq_len\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_u)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        iid = self.df_i[idx]\n",
    "        uid = self.df_u[idx]\n",
    "        \n",
    "        idx = uid\n",
    "        target_pos = self.inv_index[uid][iid]\n",
    "        \n",
    "        \n",
    "        history = self.histories[idx]\n",
    "        timespents = self.timespents[idx]\n",
    "        reactions = self.reactions[idx]\n",
    "        \n",
    "        # Generate length of history(activities) that would represent user\n",
    "        hist_len = self.seq_len + randint(-3, 0)\n",
    "        hist_len = min(hist_len, target_pos)\n",
    "        \n",
    "        # Takes all available history\n",
    "        if self.mode == 'eval':\n",
    "            hist_len = target_pos\n",
    "        \n",
    "        target_id = iid\n",
    "        # Time spent on target post\n",
    "        label = timespents[target_pos]\n",
    "        # History features\n",
    "        history_ids = history[target_pos - hist_len:target_pos]\n",
    "        \n",
    "        # Use embeddings to create features\n",
    "        history_embs = self.item_embs[history_ids]\n",
    "        ts = np.array([timespents[target_pos - hist_len:target_pos]])\n",
    "        rs = np.array([reactions[target_pos - hist_len:target_pos]])\n",
    "        history_features = np.hstack([history_embs, ts.T, rs.T])\n",
    "        \n",
    "        # Checks for self interaction\n",
    "        self_interaction = int(self.items_sources[target_id] == idx)\n",
    "        \n",
    "        # Pack to tensors\n",
    "        history_features = torch.FloatTensor(history_features)\n",
    "        other = torch.FloatTensor(np.concatenate([ \\\n",
    "              self.user_embs[idx], \\\n",
    "              self.item_embs[target_id], \\\n",
    "              [self_interaction]]))\n",
    "        label = torch.FloatTensor([label])\n",
    "        \n",
    "        return  history_features, other, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(Sampler):\n",
    "    def __init__(self, train_u_i, num_samples=2**18):        \n",
    "        grouped = train_u_i.groupby('timespent')\n",
    "        time_freqs = grouped.size()\n",
    "        ws = [1. / 61 for i in range(61)]\n",
    "        for i in range(61):\n",
    "            if i not in grouped.indices:\n",
    "                ws[i] = 0.\n",
    "                \n",
    "        self.cat = torch.distributions.categorical.Categorical(torch.tensor(ws))\n",
    "        self.time_freqs = time_freqs\n",
    "        self.num_samples = num_samples\n",
    "        self.indices = grouped.indices\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        times = self.cat.sample((self.num_samples, ))\n",
    "        ids = []\n",
    "        \n",
    "        rands = torch.rand(len(times))\n",
    "        for i, time in enumerate(times):\n",
    "            time = time.item()\n",
    "            ids.append(self.indices[time][int((self.time_freqs[time] * rands[i]).item())])\n",
    "        return (i for i in ids)  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (hist, emb, label) = zip(*batch)\n",
    "    bs = len(emb)\n",
    "    \n",
    "    hist_pad = torch.nn.utils.rnn.pad_sequence(list(hist), batch_first=True)\n",
    "\n",
    "    return hist_pad, torch.cat(emb).reshape(bs, -1), torch.cat(label).reshape(bs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared error\n",
    "def se(preds, target):\n",
    "    return ((preds - target)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, lr=1e-5, l2=1e-8, max_lr=1e-3, \n",
    "                iters=100, save_rate=10, prefix='default'):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, \n",
    "                                                    steps_per_epoch=len(train_loader), epochs=iters)\n",
    "    \n",
    "    dists = torch.zeros(61)\n",
    "    for it in range(iters):\n",
    "        print(f'Iteration {it}')\n",
    "        # Train\n",
    "        for i, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            # forward\n",
    "            preds = model(batch[0].to(device), batch[1].to(device))\n",
    "            \n",
    "            loss = loss_fn(preds, batch[2].to(device))\n",
    "            \n",
    "            for time in batch[2].detach().flatten().tolist():\n",
    "                dists[int(time)] += 1\n",
    "            \n",
    "            wandb.log({\n",
    "                \"loss\": loss.item()\n",
    "            })\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            # update\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # zerograd\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate validation mse\n",
    "        if it % 3 == 0:\n",
    "            model.eval()\n",
    "            mse = 0.\n",
    "            with torch.no_grad():\n",
    "                for i, batch in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "                    preds = model(batch[0].to(device), batch[1].to(device))\n",
    "                    mse += se(preds.flatten(), batch[2].flatten().to('cuda')).item()\n",
    "\n",
    "            mse /= (len(val_loader) * CFG['valid_bs'])\n",
    "            model.train()\n",
    "            \n",
    "            wandb.log({\"val_mse\" : mse})\n",
    "        \n",
    "        # Log class distribution\n",
    "        data = [[i, dists[i]] for i in range(61)]\n",
    "        table = wandb.Table(data=data, columns = [\"class\", \"samples\"])\n",
    "        wandb.log({\"class_distribution\" : wandb.plot.bar(table, \"class\", \"samples\",\n",
    "                               title=\"Class distribution\")})\n",
    "        \n",
    "        # Make ckpt\n",
    "        if it % save_rate == 0:\n",
    "            path = f\"models/{prefix}-ckpt_iteration_{it}.pt\"\n",
    "            torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4421"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create additional features for user\n",
    "users_stats = train.groupby('user_id').agg(\n",
    "    avg_time  = pd.NamedAgg(column = 'timespent', aggfunc = 'mean'),\n",
    "    items_cnt = pd.NamedAgg(column = 'item_id',   aggfunc = lambda x: len(set(x))),\n",
    "    likes     = pd.NamedAgg(column = 'reaction',  aggfunc = lambda x: (x == 1).sum()),\n",
    "    dislikes  = pd.NamedAgg(column = 'reaction',  aggfunc = lambda x: (x == -1).sum())\n",
    ")\n",
    "users_extended = np.hstack([user_embs, users_stats[['avg_time', 'items_cnt', 'likes', 'dislikes']].values])\n",
    "\n",
    "del train, users_stats, user_embs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_u_i, train_df, items_meta, \n",
    "                          users_extended, extended_embeddings, \n",
    "                          seq_len=seq_len, mode='train')\n",
    "\n",
    "val_dataset = MyDataset(val_u_i, val_df, items_meta, \n",
    "                        users_extended, extended_embeddings, \n",
    "                        seq_len=seq_len, mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    sampler=ImbalancedDatasetSampler(train_u_i, num_samples=CFG['num_samples']),\n",
    "    batch_size=CFG['train_bs'],\n",
    "    collate_fn=pad_collate,\n",
    "    num_workers=CFG['num_workers'],\n",
    "    pin_memory=True,\n",
    "    pin_memory_device='cuda'\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=ImbalancedDatasetSampler(val_u_i, num_samples=CFG['num_samples']),\n",
    "    batch_size=CFG['valid_bs'],\n",
    "    collate_fn=pad_collate,\n",
    "    num_workers=CFG['num_workers'],\n",
    "    pin_memory=True,\n",
    "    pin_memory_device='cuda'\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    'lr' : CFG['lr'],\n",
    "    'max_lr' : CFG['lr'] * 2.,\n",
    "    'l2' : CFG['weight_decay'],\n",
    "    'iters' : CFG['iters']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"VK-cup-recommender\",\n",
    "\n",
    "    config = {\n",
    "        **hypers\n",
    "    }\n",
    ")\n",
    "\n",
    "prefix = 'balanced'\n",
    "model = TimespentRegressor().to(device)\n",
    "wandb.watch(model)\n",
    "\n",
    "train_model(model, train_loader, val_loader, prefix=prefix, save_rate=15,  **hypers)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "path = f\"models/{prefix}_iteration_{CFG['iters']}.pt\"\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = TimespentRegressor().to(device)\n",
    "# model.load_state_dict(torch.load('models/balanced-ckpt_iteration_250.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|      Modules      | Parameters |\n",
      "+-------------------+------------+\n",
      "| lstm.weight_ih_l0 |   404496   |\n",
      "| lstm.weight_hh_l0 |   404496   |\n",
      "|  lstm.bias_ih_l0  |    1272    |\n",
      "|  lstm.bias_hh_l0  |    1272    |\n",
      "|     bn0.weight    |    318     |\n",
      "|      bn0.bias     |    318     |\n",
      "|     fc1.weight    |   60864    |\n",
      "|     bn1.weight    |     64     |\n",
      "|      bn1.bias     |     64     |\n",
      "|     fc2.weight    |     64     |\n",
      "|      fc2.bias     |     1      |\n",
      "+-------------------+------------+\n",
      "Total Trainable Params: 873229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "873229"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ds, _ = leave_last_k_out_split(train, k = 0)\n",
    "\n",
    "candidate_items = candidates_df.item_id.values\n",
    "\n",
    "hists = processed_ds['item_ids'].values\n",
    "timespents = processed_ds['timespents'].values\n",
    "reactions = processed_ds['reactions'].values\n",
    "items_sources = items_meta['source_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_ids, predictions, mf_scores):\n",
    "    final_preds = []\n",
    "    for i, user_id in tqdm(enumerate(test_ids), total = len(test_ids)):\n",
    "        user_pred = []\n",
    "        scrs = score_items(model, user_id, predictions[i]).flatten()\n",
    "        \n",
    "        # NN score\n",
    "        scrs /= 60.\n",
    "        scrs = scrs.to('cpu')\n",
    "        # score + similarity\n",
    "        scrs += mf_scores[i]\n",
    "        \n",
    "        t_scores = scrs.tolist()\n",
    "        ss = sorted(t_scores)[::-1]\n",
    "        for i in range(20):\n",
    "            idx = t_scores.index(ss[i])\n",
    "            user_pred.append(predictions[i][idx])\n",
    "\n",
    "        final_preds.append(user_pred)\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_items(model, user_id, item_ids):\n",
    "    history = hists[user_id]\n",
    "    times = timespents[user_id]\n",
    "    likes = reactions[user_id]\n",
    "\n",
    "    target_pos = len(history)\n",
    "\n",
    "    hist_len = seq_len\n",
    "    hist_len = min(hist_len, target_pos)\n",
    "\n",
    "    history_ids = history[target_pos - hist_len:target_pos]\n",
    "\n",
    "    history_embs = extended_embeddings[history_ids]\n",
    "    ts = np.array([times[target_pos - hist_len:target_pos]])\n",
    "    rs = np.array([likes[target_pos - hist_len:target_pos]])\n",
    "    history_features = np.hstack([history_embs, ts.T, rs.T])\n",
    "\n",
    "    others = []\n",
    "    for item_id in item_ids:\n",
    "        self_interaction = int(items_sources[item_id] == user_id)\n",
    "        others.append(\n",
    "            np.concatenate(\n",
    "                [users_extended[user_id], \n",
    "                extended_embeddings[item_id], \n",
    "                [self_interaction]]\n",
    "            ))\n",
    "    \n",
    "    history_features = torch.FloatTensor(history_features).unsqueeze(0).repeat(len(item_ids), 1, 1)\n",
    "    other = torch.FloatTensor(np.array(others))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        scores = model(history_features.to(device), other.to(device))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiMgUwjChKUW",
    "outputId": "6e8f891e-8fdd-4ffe-b88c-482444a04e4b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97217f5356fb4bea901d8a0c9f35066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "scores = []\n",
    "test_ids = test.user_id.values\n",
    "bs = 512\n",
    "\n",
    "for i in tqdm(range((len(test_ids) + bs - 1) // bs)):\n",
    "    user_ids = test_ids[i*bs:(i + 1)*bs]\n",
    "    \n",
    "    ids, scrs = model_mf.recommend(user_ids, user_item_train[user_ids],\n",
    "                                  N=20,\n",
    "                                  filter_already_liked_items=True,\n",
    "                                  items=candidate_items\n",
    "                                  )\n",
    "    \n",
    "    scores.append(scrs)\n",
    "    predictions.append(ids)\n",
    "    \n",
    "scores = np.concatenate(scores)\n",
    "predictions = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bef3b7134fa4052818198e4d5b8df29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = predict(test_ids, predictions, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "PWaFNksJhKUX",
    "outputId": "116de4eb-e118-4d43-a872-2fc99647de78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[63017, 49912, 29054, 63388, 200250, 11787, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[221001, 53828, 221344, 4305, 87797, 56900, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[190377, 49912, 64601, 148826, 155056, 54559, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[221001, 97654, 108363, 2915, 2216, 217361, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[221001, 88573, 29054, 131294, 120767, 11787, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1000160</td>\n",
       "      <td>[190377, 88573, 63495, 2915, 87797, 35482, 131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1000165</td>\n",
       "      <td>[221001, 53828, 29054, 68855, 155056, 124525, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1000166</td>\n",
       "      <td>[221001, 40628, 227299, 74088, 197397, 139838,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1000168</td>\n",
       "      <td>[190377, 49912, 29054, 148826, 200250, 11787, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>1000172</td>\n",
       "      <td>[190377, 49912, 29054, 148826, 87797, 219476, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        predictions\n",
       "0             7  [63017, 49912, 29054, 63388, 200250, 11787, 46...\n",
       "1             8  [221001, 53828, 221344, 4305, 87797, 56900, 46...\n",
       "2             9  [190377, 49912, 64601, 148826, 155056, 54559, ...\n",
       "3            11  [221001, 97654, 108363, 2915, 2216, 217361, 46...\n",
       "4            18  [221001, 88573, 29054, 131294, 120767, 11787, ...\n",
       "...         ...                                                ...\n",
       "199995  1000160  [190377, 88573, 63495, 2915, 87797, 35482, 131...\n",
       "199996  1000165  [221001, 53828, 29054, 68855, 155056, 124525, ...\n",
       "199997  1000166  [221001, 40628, 227299, 74088, 197397, 139838,...\n",
       "199998  1000168  [190377, 49912, 29054, 148826, 200250, 11787, ...\n",
       "199999  1000172  [190377, 49912, 29054, 148826, 87797, 219476, ...\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predictions'] = predictions\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "C6BgX6_bhKUX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.to_parquet('sample_submission.parquet.gzip', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
